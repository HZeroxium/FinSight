# =============================================================================
# FIN SIGHT NEWS SERVICE - COMPLETE ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and customize for your environment
# All variables support environment variable override and are validated at startup

# =============================================================================
# SERVICE CONFIGURATION
# =============================================================================
# Application identification and behavior
APP_NAME=news-crawler-service
DEBUG=false
ENVIRONMENT=development
HOST=0.0.0.0
PORT=8000

# =============================================================================
# GRPC SERVER CONFIGURATION
# =============================================================================
# Enable/disable gRPC server for high-performance communication
ENABLE_GRPC=true
GRPC_HOST=0.0.0.0
GRPC_PORT=50051

# gRPC performance and resource settings
GRPC_MAX_WORKERS=10
GRPC_MAX_RECEIVE_MESSAGE_LENGTH=4194304
GRPC_MAX_SEND_MESSAGE_LENGTH=4194304

# =============================================================================
# EUREKA CLIENT CONFIGURATION
# =============================================================================
# Service discovery and registration with Eureka server
ENABLE_EUREKA_CLIENT=true
EUREKA_SERVER_URL=http://localhost:8761
EUREKA_APP_NAME=news-service

# Instance identification and networking
EUREKA_INSTANCE_ID=
EUREKA_HOST_NAME=
EUREKA_IP_ADDRESS=
EUREKA_PORT=8000
EUREKA_SECURE_PORT=8443
EUREKA_SECURE_PORT_ENABLED=false

# Instance URLs for health checks and status
EUREKA_HOME_PAGE_URL=
EUREKA_STATUS_PAGE_URL=
EUREKA_HEALTH_CHECK_URL=

# VIP addresses for load balancing
EUREKA_VIP_ADDRESS=
EUREKA_SECURE_VIP_ADDRESS=
EUREKA_PREFER_IP_ADDRESS=true

# =============================================================================
# EUREKA TIMING CONFIGURATION
# =============================================================================
# Lease management for service registration
EUREKA_LEASE_RENEWAL_INTERVAL_IN_SECONDS=30
EUREKA_LEASE_EXPIRATION_DURATION_IN_SECONDS=90

# Registry operations and synchronization
EUREKA_REGISTRY_FETCH_INTERVAL_SECONDS=30
EUREKA_INSTANCE_INFO_REPLICATION_INTERVAL_SECONDS=30
EUREKA_INITIAL_INSTANCE_INFO_REPLICATION_INTERVAL_SECONDS=40

# Heartbeat settings for service health monitoring
EUREKA_HEARTBEAT_INTERVAL_SECONDS=30

# =============================================================================
# EUREKA RETRY CONFIGURATION
# =============================================================================
# Registration retry settings with exponential backoff
EUREKA_REGISTRATION_RETRY_ATTEMPTS=3
EUREKA_REGISTRATION_RETRY_DELAY_SECONDS=5

# Heartbeat retry settings for connection resilience
EUREKA_HEARTBEAT_RETRY_ATTEMPTS=3
EUREKA_HEARTBEAT_RETRY_DELAY_SECONDS=2

# Retry backoff configuration for network issues
EUREKA_RETRY_BACKOFF_MULTIPLIER=2.0
EUREKA_MAX_RETRY_DELAY_SECONDS=60

# Auto-reregistration for service recovery
EUREKA_ENABLE_AUTO_RE_REGISTRATION=true
EUREKA_RE_REGISTRATION_DELAY_SECONDS=10

# =============================================================================
# EXTERNAL API CONFIGURATION
# =============================================================================
# Tavily search engine API for news discovery
TAVILY_API_KEY=

# Admin API secret key for job management and administrative operations
SECRET_API_KEY=

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# Database environment selection (local/cloud)
DATABASE_ENVIRONMENT=local

# MongoDB local connection settings
MONGODB_LOCAL_URL=mongodb://localhost:27017
MONGODB_LOCAL_DATABASE=finsight_coindesk_news

# MongoDB cloud connection (Atlas) - required when DATABASE_ENVIRONMENT=cloud
MONGODB_CLOUD_URL=
MONGODB_CLOUD_DATABASE=finsight_news

# Collection configuration for news storage
MONGODB_COLLECTION_NEWS=news_items

# =============================================================================
# MONGODB CONNECTION OPTIONS
# =============================================================================
# Connection timeouts and pool settings for performance optimization
MONGODB_CONNECTION_TIMEOUT=10000
MONGODB_SERVER_SELECTION_TIMEOUT=5000
MONGODB_MAX_POOL_SIZE=10
MONGODB_MIN_POOL_SIZE=1

# =============================================================================
# RABBITMQ MESSAGE BROKER CONFIGURATION
# =============================================================================
# RabbitMQ connection URL for inter-service communication
RABBITMQ_URL=amqp://guest:guest@localhost:5672/

# Single exchange for all news events (unified messaging)
RABBITMQ_EXCHANGE=news.event

# Queue names for different message types
RABBITMQ_QUEUE_NEWS_TO_SENTIMENT=news.sentiment_analysis
RABBITMQ_QUEUE_SENTIMENT_RESULTS=sentiment.results

# Routing keys for message routing and filtering
RABBITMQ_ROUTING_KEY_NEWS_TO_SENTIMENT=news.sentiment.analyze
RABBITMQ_ROUTING_KEY_SENTIMENT_RESULTS=sentiment.results.processed

# =============================================================================
# NEWS CRAWLER CONFIGURATION
# =============================================================================
# Advanced crawling features for enhanced news collection
ENABLE_ADVANCED_CRAWLING=true

# Performance and concurrency settings
MAX_CONCURRENT_CRAWLS=10
CRAWL_TIMEOUT=30
CRAWL_RETRY_ATTEMPTS=3

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================
# Enable/disable caching for performance optimization
ENABLE_CACHING=true
CACHE_TTL_SECONDS=300

# =============================================================================
# REDIS CACHE CONFIGURATION
# =============================================================================
# Redis connection settings for distributed caching
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Redis key prefix for news service namespace
REDIS_KEY_PREFIX=news-service:

# Redis connection timeouts and options
REDIS_CONNECTION_TIMEOUT=5
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5
REDIS_SOCKET_KEEPALIVE=true
REDIS_RETRY_ON_TIMEOUT=true
REDIS_MAX_CONNECTIONS=10

# =============================================================================
# CACHE TTL CONFIGURATION FOR DIFFERENT ENDPOINTS
# =============================================================================
# TTL settings for different API endpoints (in seconds)
# Search news - longer TTL for search results
CACHE_TTL_SEARCH_NEWS=1800
# Recent news - shorter TTL for time-sensitive content
CACHE_TTL_RECENT_NEWS=900
# News by source - medium TTL for source-based queries
CACHE_TTL_NEWS_BY_SOURCE=1800
# News by keywords - medium TTL for keyword searches
CACHE_TTL_NEWS_BY_KEYWORDS=1200
# News by tags - medium TTL for tag-based queries
CACHE_TTL_NEWS_BY_TAGS=1800
# Available tags - longer TTL for tag metadata
CACHE_TTL_AVAILABLE_TAGS=3600
# Repository stats - shorter TTL for dynamic statistics
CACHE_TTL_REPOSITORY_STATS=600
# Individual news item - longer TTL for article content
CACHE_TTL_NEWS_ITEM=7200

# =============================================================================
# CACHE INVALIDATION CONFIGURATION
# =============================================================================
# Cache invalidation for data consistency
CACHE_INVALIDATION_ENABLED=true
CACHE_INVALIDATION_PATTERN=news-service:*
CACHE_INVALIDATION_DELAY_SECONDS=5

# =============================================================================
# RATE LIMITING CONFIGURATION
# =============================================================================
# API rate limiting to prevent abuse and ensure fair usage
RATE_LIMIT_REQUESTS_PER_MINUTE=100

# =============================================================================
# CRON JOB CONFIGURATION
# =============================================================================
# Automated news collection scheduling
CRON_JOB_ENABLED=true
# Cron schedule (every 6 hours by default) - format: minute hour day month weekday
CRON_JOB_SCHEDULE=0 */6 * * *

# Job limits and configuration
CRON_JOB_MAX_ITEMS_PER_SOURCE=100
# Comma-separated list of news sources to crawl
CRON_JOB_SOURCES=coindesk,cointelegraph
CRON_JOB_CONFIG_FILE=news_crawler_config.json
CRON_JOB_PID_FILE=news_crawler_job.pid
CRON_JOB_LOG_FILE=logs/news_crawler_job.log

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Log level and file settings for debugging and monitoring
LOG_LEVEL=INFO
LOG_FILE_PATH=logs/

# Structured logging for better log analysis and monitoring
ENABLE_STRUCTURED_LOGGING=true

# =============================================================================
# VALIDATION RULES AND CONSTRAINTS
# =============================================================================
# The following constraints are automatically enforced:

# MAX_CONCURRENT_CRAWLS: 1-100
# CRAWL_TIMEOUT: 5-300 seconds
# CRAWL_RETRY_ATTEMPTS: 1-10
# EUREKA_LEASE_RENEWAL_INTERVAL: 1-300 seconds
# EUREKA_LEASE_EXPIRATION_DURATION: 30-900 seconds
# EUREKA_REGISTRATION_RETRY_ATTEMPTS: 1-10
# EUREKA_HEARTBEAT_RETRY_ATTEMPTS: 1-10
# EUREKA_RETRY_BACKOFF_MULTIPLIER: 1.0-5.0
# CACHE_TTL_SEARCH_NEWS: 60-7200 seconds
# CACHE_TTL_RECENT_NEWS: 60-3600 seconds
# REDIS_MAX_CONNECTIONS: 1-100

# =============================================================================
# ENVIRONMENT-SPECIFIC CONFIGURATION EXAMPLES
# =============================================================================

# Development Environment
# DEBUG=true
# LOG_LEVEL=DEBUG
# ENVIRONMENT=development
# CACHE_TTL_SECONDS=60

# Staging Environment
# DEBUG=false
# LOG_LEVEL=INFO
# ENVIRONMENT=staging
# CACHE_TTL_SECONDS=300

# Production Environment
# DEBUG=false
# LOG_LEVEL=WARNING
# ENVIRONMENT=production
# CACHE_TTL_SECONDS=1800
# ENABLE_STRUCTURED_LOGGING=true
# ENABLE_ADVANCED_CRAWLING=true
# MAX_CONCURRENT_CRAWLS=20

# =============================================================================
# SECURITY CONSIDERATIONS
# =============================================================================
# 1. Never commit API keys or secrets to version control
# 2. Use environment variables for all sensitive configuration
# 3. Rotate API keys regularly
# 4. Use strong, unique API keys for each environment
# 5. Monitor API usage and implement rate limiting
# 6. Use HTTPS in production environments
# 7. Implement proper authentication for admin endpoints
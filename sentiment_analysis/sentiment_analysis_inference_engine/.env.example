# Triton Server Configuration
TRITON_HOST=localhost
TRITON_HTTP_PORT=8000
TRITON_GRPC_PORT=8001
TRITON_METRICS_PORT=8002
TRITON_MODEL_REPOSITORY=../sentiment_analysis_model_builder/models/triton_model_repository
TRITON_MODEL_NAME=finbert_sentiment
TRITON_DOCKER_IMAGE=nvcr.io/nvidia/tritonserver:23.10-py3
TRITON_CONTAINER_NAME=triton-inference-server
TRITON_STARTUP_TIMEOUT=120
TRITON_HEALTH_CHECK_INTERVAL=5
TRITON_GPU_ENABLED=true
TRITON_GPU_MEMORY_FRACTION=0.8

# Sentiment Analysis Configuration
SENTIMENT_MODEL_NAME=finbert_sentiment
SENTIMENT_TOKENIZER_NAME=ProsusAI/finbert
SENTIMENT_MAX_LENGTH=512
SENTIMENT_MAX_BATCH_SIZE=32
SENTIMENT_BATCH_TIMEOUT_MS=100
SENTIMENT_CACHE_SIZE=1000
SENTIMENT_CACHE_TTL=3600

# API Configuration
API_HOST=0.0.0.0
API_PORT=8080
API_RELOAD=false
API_LOG_LEVEL=INFO
API_ACCESS_LOG=true
API_RATE_LIMIT_ENABLED=true
API_RATE_LIMIT_REQUESTS=100
API_REQUEST_TIMEOUT=30

# CORS Configuration
API_ALLOW_ORIGINS=["*"]
API_ALLOW_METHODS=["GET", "POST"]
API_ALLOW_HEADERS=["*"]

# Global Configuration
ENVIRONMENT=development
DEBUG=false
LOG_DIR=logs
DATA_DIR=data

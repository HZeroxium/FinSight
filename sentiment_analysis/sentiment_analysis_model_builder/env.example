# =============================================================================
# FIN SIGHT SENTIMENT ANALYSIS MODEL BUILDER - COMPLETE ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and customize for your environment
# All variables support environment variable override and are validated at startup

# =============================================================================
# GLOBAL SETTINGS
# =============================================================================
# Global configuration for the model builder service
LOG_LEVEL=INFO
OUTPUT_DIR=outputs
CACHE_DIR=.cache

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
# Input data configuration for model training
DATA_INPUT_PATH=data/news_dataset_sample.json
DATA_INPUT_FORMAT=json

# Required column mappings for sentiment analysis
DATA_TEXT_COLUMN=text
DATA_LABEL_COLUMN=label

# Optional column mappings for enhanced data processing
DATA_ID_COLUMN=id
DATA_TITLE_COLUMN=title
DATA_PUBLISHED_AT_COLUMN=published_at
DATA_TICKERS_COLUMN=tickers
DATA_SPLIT_COLUMN=split

# Data validation and processing settings
DATA_VALIDATE_DATA=true
# Maximum number of samples to load (leave empty for all data)
DATA_MAX_SAMPLES=

# =============================================================================
# PREPROCESSING CONFIGURATION
# =============================================================================
# Text cleaning and preprocessing options
PREPROCESSING_REMOVE_HTML=true
PREPROCESSING_NORMALIZE_UNICODE=true
PREPROCESSING_LOWERCASE=true
PREPROCESSING_REMOVE_URLS=true
PREPROCESSING_REMOVE_EMAILS=true

# Text length constraints for model input
# FinBERT supports maximum 512 tokens (~2048 characters)
PREPROCESSING_MAX_LENGTH=512
PREPROCESSING_MIN_LENGTH=10

# Label mapping for sentiment classification
# Format: {"NEGATIVE": 0, "NEUTRAL": 1, "POSITIVE": 2}
PREPROCESSING_LABEL_MAPPING={"NEGATIVE": 0, "NEUTRAL": 1, "POSITIVE": 2}

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================
# Model backbone selection for training
# Supported: ProsusAI/finbert, microsoft/DialoGPT-medium, etc.
TRAINING_BACKBONE=ProsusAI/finbert

# Training hyperparameters
TRAINING_BATCH_SIZE=16
TRAINING_EVAL_BATCH_SIZE=32
TRAINING_LEARNING_RATE=2e-5
TRAINING_NUM_EPOCHS=3
TRAINING_WARMUP_STEPS=500
TRAINING_WEIGHT_DECAY=0.01
TRAINING_GRADIENT_CLIP_VAL=1.0

# Data splitting configuration
TRAINING_TRAIN_SPLIT=0.7
TRAINING_VAL_SPLIT=0.15
TRAINING_TEST_SPLIT=0.15
TRAINING_RANDOM_SEED=42

# Early stopping configuration
TRAINING_EARLY_STOPPING_PATIENCE=3
TRAINING_EARLY_STOPPING_THRESHOLD=0.001

# Primary metric for model evaluation
# Supported: f1_macro, accuracy, precision, recall
TRAINING_PRIMARY_METRIC=f1_macro

# =============================================================================
# TRAINING EVALUATION AND LOGGING
# =============================================================================
# Evaluation strategy and frequency
# Supported: steps, epoch, no
TRAINING_EVALUATION_STRATEGY=steps
TRAINING_EVAL_STEPS=20
TRAINING_LOGGING_STEPS=20

# Model saving configuration
TRAINING_SAVE_STEPS=500
TRAINING_SAVE_TOTAL_LIMIT=3
# Supported: steps, epoch, no
TRAINING_SAVE_STRATEGY=steps

# =============================================================================
# EXPORT CONFIGURATION
# =============================================================================
# Export format for the trained model
# Supported: onnx, torchscript, pytorch
EXPORT_FORMAT=onnx

# ONNX-specific export settings
EXPORT_ONNX_OPSET_VERSION=17
EXPORT_ONNX_DYNAMIC_AXES=true

# Output directory for exported models
EXPORT_OUTPUT_DIR=models/exported

# Export validation and testing
EXPORT_VALIDATE_EXPORT=true
EXPORT_TEST_BATCH_SIZE=1

# =============================================================================
# REGISTRY CONFIGURATION (MLflow)
# =============================================================================
# MLflow tracking server configuration
REGISTRY_TRACKING_URI=http://localhost:5000
REGISTRY_REGISTRY_URI=
REGISTRY_BACKEND_STORE_URI=sqlite:///mlflow.db

# Model registry settings
REGISTRY_MODEL_NAME=crypto-news-sentiment
# Supported stages: Staging, Production, Archived
REGISTRY_MODEL_STAGE=Staging

# Artifact storage location (S3/MinIO compatible)
REGISTRY_ARTIFACT_LOCATION=s3://mlflow-artifacts/

# MLflow server configuration
REGISTRY_MLFLOW_HOST=0.0.0.0
REGISTRY_MLFLOW_PORT=5000

# =============================================================================
# MINIO CONFIGURATION (S3-COMPATIBLE STORAGE)
# =============================================================================
# MinIO credentials for artifact storage
REGISTRY_AWS_ACCESS_KEY_ID=minioadmin
REGISTRY_AWS_SECRET_ACCESS_KEY=minioadmin
REGISTRY_AWS_REGION=us-east-1
REGISTRY_S3_ENDPOINT_URL=http://localhost:9000

# =============================================================================
# API CONFIGURATION
# =============================================================================
# API server settings
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
API_RELOAD=false

# API metadata and documentation
API_TITLE="FinBERT Sentiment Analysis API"
API_DESCRIPTION="RESTful API for financial sentiment analysis using fine-tuned FinBERT"
API_VERSION=1.0.0

# =============================================================================
# MODEL CONFIGURATION FOR API
# =============================================================================
# Paths to trained model artifacts
API_MODEL_PATH=outputs/model
API_PREPROCESSING_CONFIG_PATH=outputs/preprocessing_config.json
API_LABEL_MAPPING_PATH=outputs/id2label.json

# =============================================================================
# INFERENCE SETTINGS
# =============================================================================
# Batch processing and performance settings
API_MAX_BATCH_SIZE=32
API_MAX_TEXT_LENGTH=512
# Supported: auto, cpu, cuda
API_DEVICE=auto

# =============================================================================
# CORS SETTINGS
# =============================================================================
# Cross-Origin Resource Sharing configuration
API_ALLOW_ORIGINS=["*"]
API_ALLOW_CREDENTIALS=true
API_ALLOW_METHODS=["*"]
API_ALLOW_HEADERS=["*"]

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Worker processes and timeout configuration
API_WORKERS=1
API_TIMEOUT=30

# =============================================================================
# VALIDATION RULES AND CONSTRAINTS
# =============================================================================
# The following constraints are automatically enforced:

# PREPROCESSING_MAX_LENGTH: 64-512 tokens
# PREPROCESSING_MIN_LENGTH: 1-2048 characters
# TRAINING_BATCH_SIZE: 1-128
# TRAINING_LEARNING_RATE: 1e-6 to 1e-2
# TRAINING_TRAIN_SPLIT: 0.1-0.9
# TRAINING_VAL_SPLIT: 0.05-0.3
# TRAINING_TEST_SPLIT: 0.05-0.3
# TRAINING_EARLY_STOPPING_PATIENCE: 1-10
# EXPORT_ONNX_OPSET_VERSION: 11-18
# API_MAX_BATCH_SIZE: 1-128
# API_MAX_TEXT_LENGTH: 64-512
# API_PORT: 1-65535
# REGISTRY_MLFLOW_PORT: 1-65535

# =============================================================================
# ENVIRONMENT-SPECIFIC CONFIGURATION EXAMPLES
# =============================================================================

# Development Environment
# LOG_LEVEL=DEBUG
# API_DEBUG=true
# API_RELOAD=true
# TRAINING_NUM_EPOCHS=1
# TRAINING_BATCH_SIZE=8
# EXPORT_VALIDATE_EXPORT=false

# Staging Environment
# LOG_LEVEL=INFO
# API_DEBUG=false
# API_RELOAD=false
# TRAINING_NUM_EPOCHS=2
# TRAINING_BATCH_SIZE=16
# EXPORT_VALIDATE_EXPORT=true

# Production Environment
# LOG_LEVEL=WARNING
# API_DEBUG=false
# API_RELOAD=false
# TRAINING_NUM_EPOCHS=5
# TRAINING_BATCH_SIZE=32
# EXPORT_VALIDATE_EXPORT=true
# TRAINING_EARLY_STOPPING_PATIENCE=5

# =============================================================================
# MODEL BACKBONE CONFIGURATION EXAMPLES
# =============================================================================

# FinBERT for Financial Text
# TRAINING_BACKBONE=ProsusAI/finbert
# PREPROCESSING_MAX_LENGTH=512
# PREPROCESSING_LOWERCASE=false

# BERT Base for General Text
# TRAINING_BACKBONE=bert-base-uncased
# PREPROCESSING_MAX_LENGTH=512
# PREPROCESSING_LOWERCASE=true

# RoBERTa for Robust Training
# TRAINING_BACKBONE=roberta-base
# PREPROCESSING_MAX_LENGTH=512
# PREPROCESSING_LOWERCASE=false

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# High Throughput Configuration
# TRAINING_BATCH_SIZE=64
# TRAINING_EVAL_BATCH_SIZE=128
# API_MAX_BATCH_SIZE=64
# API_WORKERS=4

# Low Memory Configuration
# TRAINING_BATCH_SIZE=8
# TRAINING_EVAL_BATCH_SIZE=16
# API_MAX_BATCH_SIZE=16
# API_WORKERS=1

# High Quality Configuration
# TRAINING_NUM_EPOCHS=10
# TRAINING_LEARNING_RATE=1e-5
# TRAINING_WARMUP_STEPS=1000
# TRAINING_EARLY_STOPPING_PATIENCE=5

# =============================================================================
# EXPORT FORMAT CONFIGURATION EXAMPLES
# =============================================================================

# ONNX Export (Recommended for production)
# EXPORT_FORMAT=onnx
# EXPORT_ONNX_OPSET_VERSION=17
# EXPORT_ONNX_DYNAMIC_AXES=true

# TorchScript Export
# EXPORT_FORMAT=torchscript
# EXPORT_VALIDATE_EXPORT=true

# PyTorch Export (Default)
# EXPORT_FORMAT=pytorch
# EXPORT_VALIDATE_EXPORT=false

# =============================================================================
# MLflow Integration Examples
# =============================================================================

# Local MLflow Server
# REGISTRY_TRACKING_URI=http://localhost:5000
# REGISTRY_BACKEND_STORE_URI=sqlite:///mlflow.db

# Remote MLflow Server
# REGISTRY_TRACKING_URI=https://mlflow.your-domain.com
# REGISTRY_REGISTRY_URI=https://mlflow.your-domain.com

# MinIO Artifact Storage
# REGISTRY_ARTIFACT_LOCATION=s3://mlflow-artifacts/
# REGISTRY_S3_ENDPOINT_URL=http://localhost:9000

# AWS S3 Artifact Storage
# REGISTRY_ARTIFACT_LOCATION=s3://your-bucket/mlflow/
# REGISTRY_AWS_REGION=us-east-1

# =============================================================================
# SECURITY CONSIDERATIONS
# =============================================================================
# 1. Never commit API keys or secrets to version control
# 2. Use environment variables for all sensitive configuration
# 3. Secure MLflow server with authentication
# 4. Use HTTPS for remote MLflow servers
# 5. Implement proper access controls for model registry
# 6. Monitor and log all model training and deployment
# 7. Validate all input data before processing
# 8. Implement proper error handling for API failures
# 9. Use secure artifact storage with proper access controls
# 10. Regularly update model dependencies and security patches

# =============================================================================
# MONITORING AND OBSERVABILITY
# =============================================================================
# Configure appropriate log levels for different environments
# Development: LOG_LEVEL=DEBUG
# Staging: LOG_LEVEL=INFO
# Production: LOG_LEVEL=WARNING

# Monitor key metrics:
# - Training loss and validation metrics
# - Model export success/failure rates
# - API response times and throughput
# - Model inference accuracy
# - MLflow experiment tracking
# - Artifact storage operations
# - GPU/CPU utilization during training
# - Memory usage during inference
